<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Model Basics — How AI Models Are Built, Trained & Used</title>
    <link rel="stylesheet" href="../styles.css">
    <style>
        /* Base styles if external sheet is missing */
        :root {
            --primary: #2c3e50;
            --accent: #3498db;
            --text: #333;
            --card-bg: #fff;
            --border: #ddd;
            --bg: #fdfdfd;
        }
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; background: var(--bg); color: var(--text); line-height: 1.6; margin: 0; }
        .container { max-width: 800px; margin: 0 auto; padding: 20px; }
        
        /* Navigation Styles */
        .slideshow-header { display: flex; align-items: center; justify-content: space-between; flex-wrap: wrap; gap: 12px; margin-bottom: 24px; border-bottom: 1px solid var(--border); padding-bottom: 15px; }
        .slideshow-header .back-link { color: var(--accent); text-decoration: none; font-weight: 500; }
        .slideshow-header .back-link:hover { text-decoration: underline; }
        
        .slide-nav { display: flex; align-items: center; gap: 12px; }
        .slide-nav button { padding: 8px 16px; font-size: 0.9rem; cursor: pointer; background: var(--card-bg); border: 1px solid var(--border); border-radius: 6px; color: var(--primary); font-weight: 500; transition: background 0.2s; }
        .slide-nav button:hover:not(:disabled) { background: #f0f0f0; }
        .slide-nav button:disabled { opacity: 0.4; cursor: not-allowed; }
        .slide-indicator { font-size: 0.85rem; color: #666; font-weight: 500; min-width: 90px; text-align: center; }

        /* Progress Bar */
        .progress-container { width: 100%; height: 4px; background: #eee; margin-top: -10px; margin-bottom: 30px; border-radius: 2px; overflow: hidden; }
        .progress-bar { height: 100%; background: var(--accent); width: 0%; transition: width 0.3s ease; }

        /* Slide Content */
        .slide { display: none; max-width: 720px; margin: 0 auto; padding: 0 10px 40px; animation: fadeIn 0.4s ease; }
        .slide.active { display: block; }
        .slide h2 { font-size: 1.5rem; color: var(--primary); margin: 0 0 1.25rem; border-left: 5px solid var(--accent); padding-left: 15px; }
        .slide ul { margin: 0 0 0 1.25rem; padding: 0; line-height: 1.7; }
        .slide li { margin-bottom: 0.75rem; color: var(--text); }
        .slide u { text-decoration: none; border-bottom: 2px solid #dcdcdc; font-weight: 500; }
        .slide .note { background: #f8f9fa; border-left: 3px solid #ccc; padding: 10px 15px; font-size: 0.9rem; color: #555; margin-top: 15px; border-radius: 0 4px 4px 0; }

        @keyframes fadeIn { from { opacity: 0; transform: translateY(5px); } to { opacity: 1; transform: translateY(0); } }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <div class="slideshow-header">
                <a href="../" class="back-link">← Home</a>
                <div class="slide-nav">
                    <button type="button" id="btnBack" aria-label="Previous slide">Back</button>
                    <span class="slide-indicator" id="slideIndicator">Slide 1 of 16</span>
                    <button type="button" id="btnNext" aria-label="Next slide">Next</button>
                </div>
            </div>
            <div class="progress-container">
                <div class="progress-bar" id="progressBar"></div>
            </div>
            <!-- Header title removed from body to keep focus on slides, or can remain as global title -->
        </header>

        <!-- Slide 1: Intro -->
        <section class="slide active" id="intro">
            <h2>The "Black Box" Pipeline</h2>
            <ul>
                <li>When you ask an AI a question, you aren't talking to a live brain that is currently learning. You are sending data through a frozen mathematical pipeline.</li>
                <li>We’ll walk through how models are built, the critical difference between <u>training</u> and <u>inference</u>, and how advanced features like <u>Reasoning</u> and <u>Tools</u> actually work.</li>
            </ul>
        </section>

        <!-- Slide 2: Building -->
        <section class="slide" id="build">
            <h2>1. The Architecture (The Blueprint)</h2>
            <ul>
                <li>Before anything learns, engineers define the <u>Architecture</u>. Today, this is almost always a <u>Transformer</u> neural network.</li>
                <li>Key components:
                    <ul>
                        <li><strong>Parameters:</strong> The billions of "knobs" (weights) the model will adjust during training.</li>
                        <li><strong>Layers:</strong> Stacks of math operations that process information hierarchically.</li>
                        <li><strong>Context Window:</strong> The limit on how much text the model can "see" at one time.</li>
                        <li><strong>Attention:</strong> The key innovation—lets the model decide which parts of the input are most relevant when predicting each token.</li>
                    </ul>
                </li>
            </ul>
        </section>

        <!-- Slide 3: Tokenization -->
        <section class="slide" id="tokens">
            <h2>2. The Language: Tokenization</h2>
            <ul>
                <li>Models don't read words; they read numbers.</li>
                <li>A <u>Tokenizer</u> chops text into chunks called <u>tokens</u> (words, parts of words, or characters).</li>
                <li>"Ingenious" might become three tokens: `In`, `gen`, `ious`. The model processes these as a sequence of integers.</li>
                <li><strong>Crucial Concept:</strong> The model predicts the next <em>token</em>, not the next idea.</li>
                <li><strong>Multimodal models</strong> (like GPT-4, Gemini, Claude) also turn images, audio, and video into tokens—allowing the same architecture to process multiple types of input.</li>
            </ul>
        </section>

        <!-- Slide 4: Pre-Training -->
        <section class="slide" id="training">
            <h2>3. Pre-Training (The Expensive Part)</h2>
            <ul>
                <li>The model is fed massive amounts of internet text (trillions of tokens).</li>
                <li><strong>The Goal:</strong> Predict the next token in a sequence. If it guesses wrong, the <u>parameters</u> are adjusted mathematically (<u>Backpropagation</u>).</li>
                <li><strong>How it learns:</strong> The model compares its guess to the actual next token; the error is used to adjust millions of weights simultaneously using <u>gradient descent</u>.</li>
                <li>This process takes months, costs millions in energy/hardware, and results in a <u>Base Model</u>.</li>
                <li>A Base Model is like a dreamy autocomplete—it can finish a sentence, but it doesn't know how to answer questions or be helpful yet.</li>
            </ul>
        </section>

        <!-- Slide 5: Fine-Tuning -->
        <section class="slide" id="tuning">
            <h2>4. Post-Training (Teaching Manners)</h2>
            <ul>
                <li>To make the Base Model useful, we use <u>Fine-Tuning</u>.</li>
                <li><strong>SFT (Supervised Fine-Tuning):</strong> Showing the model examples of "Instruction -> Good Response" pairs.</li>
                <li><strong>RLHF (Reinforcement Learning from Human Feedback):</strong> Humans (or other models) rank the AI's answers from best to worst. The model adjusts to prefer the high-ranking behaviors (safety, helpfulness, tone).</li>
            </ul>
        </section>

        <!-- Slide 6: Inference vs Learning -->
        <section class="slide" id="inference-concept">
            <h2>5. The Big Misconception: Inference</h2>
            <ul>
                <li>Once trained, the model is <strong>Frozen</strong>.</li>
                <li>When you chat with it, this is called <u>Inference</u>. The model calculates the response, but it does NOT update its weights.</li>
                <li><strong>It does not learn from you.</strong> If you teach it a fact in a chat, it "forgets" it the moment that chat history falls out of the context window. It has no long-term memory formed during chat.</li>
            </ul>
        </section>

        <!-- Slide 7: The Prompt Stack -->
        <section class="slide" id="prompt-stack">
            <h2>6. What actually gets sent?</h2>
            <ul>
                <li>When you type "Hello", the model sees much more than that.</li>
                <li><strong>System Prompt:</strong> Hidden instructions from the developer (e.g., "You are a helpful assistant who speaks French").</li>
                <li><strong>Conversation History:</strong> The previous turns of the chat are re-sent with every new message so the model has "short-term memory."</li>
                <li><strong>User Prompt:</strong> Your actual question.</li>
            </ul>
        </section>

        <!-- Slide 8: Probabilities & Hallucination -->
        <section class="slide" id="probabilities">
            <h2>7. Probabilities & Temperature</h2>
            <ul>
                <li>The model outputs a list of <u>probabilities</u> for what the next token should be.</li>
                <li><strong>Temperature:</strong> A setting that determines how "risky" the model is.
                    <ul>
                        <li>Low Temperature (0.1): Always pick the most likely word (Precise, repetitive).</li>
                        <li>High Temperature (0.8): Sometimes pick less likely words (Creative, unpredictable).</li>
                    </ul>
                </li>
                <li><strong>Hallucination:</strong> Because it is probabilistic, the model can confidently predict a sequence of words that <em>sounds</em> true but is factually false.</li>
            </ul>
        </section>

        <!-- Slide 9: Context & RAG -->
        <section class="slide" id="rag">
            <h2>8. Cheating on the Test (RAG)</h2>
            <ul>
                <li>Since the model's knowledge is frozen at its training date, it doesn't know today's news.</li>
                <li><strong>RAG (Retrieval-Augmented Generation):</strong>
                    <ol>
                        <li>Your question is used to search a database (like Google or company files).</li>
                        <li>Relevant text is pasted into the model's <u>Context Window</u>.</li>
                        <li>The model answers your question using that new text.</li>
                    </ol>
                </li>
            </ul>
        </section>

        <!-- Slide 10: Tool Use -->
        <section class="slide" id="tools">
            <h2>9. Tool Use (Function Calling)</h2>
            <ul>
                <li>Models are bad at math and can't browse the web natively.</li>
                <li>With <u>Tool Use</u>, the model can output a specific text command (e.g., `CALCULATOR(25 * 48)`).</li>
                <li>The software pauses the model, runs the calculator code, gets `1200`, and feeds that number back to the model.</li>
                <li>The model then continues writing the sentence using the result.</li>
            </ul>
        </section>

        <!-- Slide 11: Chain of Thought -->
        <section class="slide" id="cot">
            <h2>10. Chain of Thought (Reasoning)</h2>
            <ul>
                <li>For hard logic puzzles, models use <u>Chain of Thought (CoT)</u>.</li>
                <li>The model isn't "thinking" in silence. It is generating tokens that represent steps.</li>
                <li>It explicitly writes out: "First I need to calculate X, then compare it to Y..."</li>
                <li>By putting these "thought tokens" into its own context window, it increases the accuracy of the final answer.</li>
            </ul>
        </section>

        <!-- Slide 12: Agentic Workflows -->
        <section class="slide" id="agents">
            <h2>11. Agentic Workflows (Plans & Goals)</h2>
            <ul>
                <li>Modern AI systems increasingly work with explicit <u>plans</u> and <u>goals</u>—either set by the user or proposed by the model itself.</li>
                <li><strong>Multi-step tasks:</strong> The model breaks down a goal ("Book a flight") into smaller steps (search flights, compare prices, confirm booking).</li>
                <li><strong>Iterative refinement:</strong> After each step, the model checks if it's closer to the goal and adjusts the plan if needed.</li>
                <li>This combines CoT reasoning + tool-use into longer, autonomous workflows (e.g., AutoGPT, Claude's extended thinking).</li>
            </ul>
        </section>

        <!-- Slide 13: Embeddings (Advanced) -->
        <section class="slide" id="embeddings">
            <h2>12. How does it understand meaning? (Embeddings)</h2>
            <ul>
                <li>How does it know "Dog" is related to "Puppy"?</li>
                <li><u>Embeddings</u> turn text into long lists of numbers (vectors). Concepts that are similar in meaning end up close together in mathematical space.</li>
                <li>This is why RAG searches are <strong>semantic</strong>—they find documents with similar <em>meaning</em>, not just matching keywords.</li>
                <li>Example: Searching for "feline companions" would find documents about "cats" even though the words are different.</li>
            </ul>
        </section>

        <!-- Slide 14: Summary -->
        <section class="slide" id="summary">
            <h2>13. Summary: The Pipeline</h2>
            <ul>
                <li>1. <strong>Input:</strong> System Prompt + History + User Question.</li>
                <li>2. <strong>Tokenization:</strong> Turn text to numbers.</li>
                <li>3. <strong>Inference:</strong> The frozen Neural Net processes numbers layer by layer.</li>
                <li>4. <strong>Decoding:</strong> Probabilities define the next token.</li>
                <li>5. <strong>Loop:</strong> The new token is added to the input, and the process repeats for the next word.</li>
            </ul>
        </section>

        <!-- Slide 15: Delivering the Result -->
        <section class="slide" id="delivery">
            <h2>14. Delivering the Result</h2>
            <ul>
                <li><strong>Streaming:</strong> Tokens appear one by one as they're generated—that's why you see the text "typing out" in real time.</li>
                <li><strong>Post-processing:</strong> Safety filters check the output; citations are formatted; code blocks are highlighted.</li>
                <li><strong>Tool execution:</strong> If the model called a tool (calculator, search, API), the tool finishes its action (e.g., sends the email, books the flight) and may return a confirmation to the user.</li>
                <li>The entire pipeline—from your question to the final result—happens in seconds, often while streaming individual tokens to you.</li>
            </ul>
        </section>

         <!-- Slide 16: Conclusion -->
         <section class="slide" id="conclusion">
            <h2>15. The Result</h2>
            <ul>
                <li>All of this happens in milliseconds.</li>
                <li>The result is a technology that feels like a thinking mind, but is actually a sophisticated, probabilistic next-token predictor powered by massive scale and structure.</li>
            </ul>
            <div class="note">End of presentation.</div>
        </section>

    </div>

    <script>
        (function () {
            // New expanded list of IDs
            const slideIds = [
                'intro', 
                'build', 
                'tokens', 
                'training', 
                'tuning', 
                'inference-concept', // New critical concept
                'prompt-stack',      // Split from context
                'probabilities',     // New critical concept
                'rag', 
                'tools', 
                'cot', 
                'agents',            // Agentic workflows
                'embeddings',        // Added for completeness
                'summary',
                'delivery',          // Result delivery
                'conclusion'
            ];
            
            const total = slideIds.length;
            const ui = {
                back: document.getElementById('btnBack'),
                next: document.getElementById('btnNext'),
                indicator: document.getElementById('slideIndicator'),
                bar: document.getElementById('progressBar')
            };

            function getIndexFromHash() {
                const hash = window.location.hash.slice(1);
                const i = slideIds.indexOf(hash);
                return i >= 0 ? i : 0;
            }

            function updateProgress(index) {
                const percentage = ((index + 1) / total) * 100;
                ui.bar.style.width = percentage + '%';
            }

            function showSlide(index) {
                // Bounds check
                index = Math.max(0, Math.min(index, total - 1));
                
                const id = slideIds[index];
                
                // Toggle active class
                document.querySelectorAll('.slide').forEach(el => el.classList.remove('active'));
                const slide = document.getElementById(id);
                if (slide) slide.classList.add('active');
                
                // Update State
                window.location.hash = id;
                ui.indicator.textContent = `Slide ${index + 1} of ${total}`;
                
                // Button states
                ui.back.disabled = index === 0;
                ui.next.disabled = index === total - 1;
                
                updateProgress(index);
                return index;
            }

            // Initialization
            let currentIndex = getIndexFromHash();
            showSlide(currentIndex);

            // Event Listeners
            window.addEventListener('hashchange', () => showSlide(getIndexFromHash()));
            ui.back.addEventListener('click', () => showSlide(getIndexFromHash() - 1));
            ui.next.addEventListener('click', () => showSlide(getIndexFromHash() + 1));

            // Keyboard Nav
            document.addEventListener('keydown', (e) => {
                const current = getIndexFromHash();
                if (e.key === 'ArrowLeft') { 
                    e.preventDefault(); 
                    showSlide(current - 1); 
                }
                if (e.key === 'ArrowRight') { 
                    e.preventDefault(); 
                    showSlide(current + 1); 
                }
            });
        })();
    </script>
</body>
</html>